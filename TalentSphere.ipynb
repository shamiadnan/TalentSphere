{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNT0wgdqILaliPLCqM1wueu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install -q streamlit google-generativeai gTTS PyPDF2 pyngrok\n","!pip uninstall -y google-generativeai -q\n","!pip install -qU google-generativeai==0.8.5\n"],"metadata":{"id":"-X98VAN-acZr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile tools.py\n","import google.generativeai as genai\n","from gtts import gTTS\n","import tempfile, io\n","from PyPDF2 import PdfReader\n","\n","def configure_gemini(api_key: str):\n","    genai.configure(api_key=api_key)\n","\n","def extract_pdf_text(uploaded_file) -> str:\n","    \"\"\"Extracts text locally so we only send TEXT to the model (no file API).\"\"\"\n","    try:\n","        data = uploaded_file.getvalue()\n","        reader = PdfReader(io.BytesIO(data))\n","        text = \"\\n\".join([(p.extract_text() or \"\") for p in reader.pages]).strip()\n","        # compact for context\n","        if len(text) > 12000:\n","            text = text[:6000] + \"\\n...\\n\" + text[-5800:]\n","        return text\n","    except Exception as e:\n","        print(\"Text Extraction Error:\", e)\n","        return \"\"\n","\n","def google_text_to_speech(text: str):\n","    try:\n","        tts = gTTS(text=text, lang='en', slow=False)\n","        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\")\n","        tts.save(tmp.name)\n","        return tmp.name\n","    except Exception as e:\n","        print(\"TTS Error:\", e)\n","        return None\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fV_XeP-ZetrN","executionInfo":{"status":"ok","timestamp":1764502107563,"user_tz":-330,"elapsed":8,"user":{"displayName":"Adnan Shami","userId":"06917492419072316222"}},"outputId":"e0da8706-5d0c-416a-efb2-7d0dca0d7b5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting tools.py\n"]}]},{"cell_type":"code","source":["%%writefile agent_logic.py\n","import google.generativeai as genai\n","import json\n","\n","# ----- model state -----\n","_MODEL_ID = None\n","\n","def set_model_id(mid: str):\n","    \"\"\"Called by the UI after you pick a model from the dropdown.\"\"\"\n","    global _MODEL_ID\n","    _MODEL_ID = mid\n","\n","def list_supported_models():\n","    \"\"\"Return (id, label) for models that support generateContent.\"\"\"\n","    out = []\n","    for m in genai.list_models():\n","        methods = getattr(m, \"supported_generation_methods\", []) or []\n","        if \"generateContent\" in methods:\n","            # Prefer the full resource name if present\n","            out.append(m.name)\n","    # Keep unique and sorted, most human-friendly last part\n","    out = sorted(set(out), key=lambda s: s.split(\"/\")[-1])\n","    return out\n","\n","def get_model():\n","    if not _MODEL_ID:\n","        raise RuntimeError(\"Model not selected. Call set_model_id() first.\")\n","    return genai.GenerativeModel(_MODEL_ID)\n","\n","# ---------- Recruiter (text only) ----------\n","def recruiter_agent(role, resume_text=\"\", candidate_intro=\"\"):\n","    model = get_model()\n","    ctx = resume_text or candidate_intro or \"No context provided.\"\n","    sys = (f\"You are a recruiter for {role}. \"\n","           \"Greet the candidate by name if available from the rÃ©sumÃ© and ask the FIRST technical question \"\n","           \"tailored to their skills. Keep it concise and specific.\")\n","    prompt = f\"{sys}\\n\\nRÃ©sumÃ©/Context:\\n{ctx}\"\n","    return model.generate_content(prompt).text\n","\n","def recruiter_followup(role, candidate_answer, step):\n","    model = get_model()\n","    prompt = (\n","        f\"Candidate answered: {candidate_answer}\\n\"\n","        f\"Current Step: {step}/4.\\n\"\n","        \"If step < 4: acknowledge, then ask the next deeper technical question based on their rÃ©sumÃ©.\\n\"\n","        \"If step == 4: thank them and say 'Interview Complete'. Keep it concise.\"\n","    )\n","    return model.generate_content(prompt).text\n","\n","# ---------- Trainer (communication JSON) ----------\n","def trainer_agent(role, candidate_answer):\n","    model = get_model()\n","    prompt = (\n","      f\"You are a personal interview trainer for the role {role}. \"\n","      \"Evaluate the candidate's answer for clarity, confidence, structure (STAR) and tone. \"\n","      \"Return ONLY valid minified JSON with this schema:\\n\"\n","      '{\"clarity\":0,\"confidence\":0,\"structure\":0,\"tone\":0,'\n","      '\"praise\":[],\"improvements\":[],\"drill\":\"\"}\\n'\n","      f\"Answer: {candidate_answer}\"\n","    )\n","    out = model.generate_content(prompt).text\n","    try:\n","        return json.loads(out)\n","    except:\n","        return {\"raw_output\": out}\n","\n","# ---------- Evaluator (final report JSON) ----------\n","def evaluator_agent(chat_history):\n","    model = get_model()\n","    conversation = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in chat_history][-12000:])\n","    prompt = (\n","      \"Evaluate the candidate based on the conversation.\\n\"\n","      \"Return ONLY valid minified JSON exactly matching:\\n\"\n","      '{\"candidate_name\":\"\",'\n","      '\"technical_score\":0,\"communication_score\":0,\"confidence_score\":0,'\n","      '\"overall\":0,\"strengths\":[],\"improvements\":[],\"verdict\":\"\"}\\n'\n","      f\"Conversation:\\n{conversation}\"\n","    )\n","    out = model.generate_content(prompt).text\n","    try:\n","        return json.loads(out)\n","    except:\n","        return {\"raw_output\": out}\n","\n","# ---------- Improvement Plan (skills gap + 4-week plan JSON) ----------\n","def improvement_plan_agent(role, chat_history, resume_text_snippet=\"\"):\n","    model = get_model()\n","    convo = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in chat_history][-6000:])\n","    prompt = (\n","      f\"You are a senior mentor creating a skills-gap report and a 4-week plan for a {role} candidate.\\n\"\n","      \"Use the resume/context and conversation to infer strengths and gaps.\\n\"\n","      \"Return ONLY valid minified JSON with this schema:\\n\"\n","      '{\"skills_gaps\":[],'\n","      '\"recommended_courses\":[],'\n","      '\"practice_projects\":[],'\n","      '\"daily_drills\":[],'\n","      '\"week_by_week_plan\":[{\"week\":1,\"focus\":\"\",\"tasks\":[]},{\"week\":2,\"focus\":\"\",\"tasks\":[]},{\"week\":3,\"focus\":\"\",\"tasks\":[]},{\"week\":4,\"focus\":\"\",\"tasks\":[]}]}'\n","      f\"\\nResume/context:\\n{resume_text_snippet}\\n\\nConversation:\\n{convo}\"\n","    )\n","    out = model.generate_content(prompt).text\n","    try:\n","        return json.loads(out)\n","    except:\n","        return {\"raw_output\": out}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c3MY1ETnhFkD","executionInfo":{"status":"ok","timestamp":1764502111455,"user_tz":-330,"elapsed":199,"user":{"displayName":"Adnan Shami","userId":"06917492419072316222"}},"outputId":"0cb7a5a0-4ed7-4962-c197-ae7f5b1676ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting agent_logic.py\n"]}]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","from tools import configure_gemini, extract_pdf_text, google_text_to_speech\n","from agent_logic import (\n","    recruiter_agent, recruiter_followup,\n","    trainer_agent, evaluator_agent, improvement_plan_agent,\n","    set_model_id, list_supported_models\n",")\n","\n","st.set_page_config(page_title=\"TalentSphere â€“ Intelligent Interview & Growth System\", page_icon=\"ðŸ’¼\", layout=\"wide\")\n","st.title(\"ðŸ’¼ TalentSphere â€“ Intelligent Interview & Growth System\")\n","st.caption(\"Empowering confident hiring and personal growth | Â© 2025 Adnan Shami\")\n","st.divider()\n","\n","# ---------- Sidebar ----------\n","with st.sidebar:\n","    st.header(\"âš™ï¸ Configuration\")\n","    api_key = st.text_input(\"Google AI Studio API Key\", type=\"password\")\n","\n","    # Step 1: configure & fetch models\n","    if api_key:\n","        configure_gemini(api_key)\n","        if st.button(\"ðŸ”„ Load available models\"):\n","            st.session_state['models'] = list_supported_models()\n","    models = st.session_state.get('models', [])\n","\n","    if models:\n","        chosen = st.selectbox(\"Choose model (from your key):\", models, index=0, format_func=lambda s: s.split(\"/\")[-1])\n","        set_model_id(chosen)\n","        st.success(f\"Model selected: {chosen}\")\n","    else:\n","        st.info(\"Enter API key and click 'Load available models' to populate the list.\")\n","\n","    role = st.text_input(\"Target Role\", value=\"Software Engineer\")\n","    st.markdown(\"**Candidate Input**\")\n","    pdf = st.file_uploader(\"Upload RÃ©sumÃ© (PDF) â€” Recommended\", type=\"pdf\")\n","    candidate_intro = st.text_area(\"OR type a short intro\", placeholder=\"e.g. 2 years in Python, data pipelines, MySQL...\")\n","\n","    start = st.button(\"ðŸš€ Start Interview\", type=\"primary\")\n","\n","# ---------- Session State ----------\n","ss = st.session_state\n","ss.setdefault(\"chat\", [])\n","ss.setdefault(\"step\", 0)\n","ss.setdefault(\"active\", False)\n","ss.setdefault(\"resume_text\", \"\")\n","ss['role'] = role\n","\n","# ---------- Start Flow ----------\n","if start and api_key and ('models' in ss) and ss['models']:\n","    resume_text = \"\"\n","    if pdf is not None:\n","        resume_text = extract_pdf_text(pdf)\n","        if resume_text:\n","            st.sidebar.success(\"RÃ©sumÃ© parsed âœ“\")\n","    ss.resume_text = resume_text\n","\n","    first_msg = recruiter_agent(role=role, resume_text=resume_text, candidate_intro=candidate_intro)\n","    ss.chat = [{\"role\": \"assistant\", \"content\": first_msg}]\n","    ss.step = 1\n","    ss.active = True\n","    st.rerun()\n","\n","# ---------- Chat UI ----------\n","for msg in ss.chat:\n","    with st.chat_message(msg[\"role\"]):\n","        st.write(msg[\"content\"])\n","        if msg[\"role\"] == \"assistant\":\n","            audio = google_text_to_speech(msg[\"content\"])\n","            if audio: st.audio(audio)\n","\n","# ---------- Turn-taking ----------\n","if user := st.chat_input(\"Your answer...\"):\n","    if ss.active:\n","        ss.chat.append({\"role\": \"user\", \"content\": user})\n","\n","        fb = trainer_agent(ss['role'], user)\n","        ss.chat.append({\"role\": \"assistant\", \"content\": f\"ðŸŽ¯ Trainer Feedback: {fb}\"})\n","\n","        if ss.step >= 4:\n","            with st.spinner(\"Generating Final Evaluation & Growth Plan...\"):\n","                report = evaluator_agent(ss.chat)\n","                plan = improvement_plan_agent(ss['role'], ss.chat, ss.resume_text[:1500])\n","            st.success(\"âœ… Interview Complete!\")\n","            st.markdown(\"### ðŸ“‹ Final Evaluation\")\n","            st.json(report)\n","            st.markdown(\"### ðŸ§­ Skills-Gap & 4-Week Growth Plan\")\n","            st.json(plan)\n","            ss.active = False\n","        else:\n","            response = recruiter_followup(ss['role'], user, ss.step)\n","            ss.step += 1\n","            ss.chat.append({\"role\": \"assistant\", \"content\": response})\n","        st.rerun()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_67LcNmkhLRE","executionInfo":{"status":"ok","timestamp":1764502122960,"user_tz":-330,"elapsed":763,"user":{"displayName":"Adnan Shami","userId":"06917492419072316222"}},"outputId":"d6ebf9ab-5161-4614-c3b6-d356d6a60121"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","source":["from pyngrok import ngrok, conf\n","import subprocess, sys, time\n","\n","NGROK_AUTH_TOKEN = \"36BcLEmYraAvQMl5bpemdzR1nU5_7ontawGJsf4UPJQQ7Q8qf\"\n","conf.get_default().region = \"in\"   # change if needed\n","\n","ngrok.kill()\n","!pkill -f \"streamlit\" || true\n","\n","proc = subprocess.Popen([sys.executable, \"-m\", \"streamlit\", \"run\", \"app.py\",\n","                         \"--server.port\", \"8501\", \"--server.headless\", \"true\"])\n","time.sleep(5)\n","\n","ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n","public_url = ngrok.connect(8501, \"http\").public_url\n","print(\"ðŸŒ Live App URL:\", public_url)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"85MLS0Cfe-FD","executionInfo":{"status":"ok","timestamp":1764502135539,"user_tz":-330,"elapsed":6653,"user":{"displayName":"Adnan Shami","userId":"06917492419072316222"}},"outputId":"6d0a4ac2-1e13-42b6-c117-f503f90ec775"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["^C\n","ðŸŒ Live App URL: https://calligraphic-eufemia-unliberalised.ngrok-free.dev\n"]}]},{"cell_type":"code","source":["!pip freeze | grep -E \"streamlit|google-generativeai|gTTS|PyPDF2|pyngrok\" > requirements.txt\n"],"metadata":{"id":"oWECc0eOlX3g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["TalentSphere/\n","â”‚\n","â”œâ”€â”€ app.py\n","â”œâ”€â”€ tools.py\n","â”œâ”€â”€ agent_logic.py\n","â”œâ”€â”€ requirements.txt\n","â”œâ”€â”€ README.md\n","â””â”€â”€ assets/\n","    â””â”€â”€ screenshot.png   (optional â€“ e.g., your Streamlit UI image)\n"],"metadata":{"id":"A7WHfqIWr3l9"}},{"cell_type":"code","source":[],"metadata":{"id":"wzxrpArIu4Re"},"execution_count":null,"outputs":[]}]}